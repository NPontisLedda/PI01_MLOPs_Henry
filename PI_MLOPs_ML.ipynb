{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En este notebook se va a llevar a cabo todo lo relacionado al modelo de Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ML= pd.read_csv('df_ML.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos columnas que no aportan información ni valor para este proceso:\n",
    "\n",
    "- Unnamed: 0 -> esta columna se agregó automaticamente cuando creamos el archivo .csv\n",
    "- developer\n",
    "- release_date\n",
    "- playtime_forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ML=df_ML.drop(columns=['Unnamed: 0','developer', 'release_date', 'playtime_forever'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se configura el modelo de Machine Learning basándonos en la similaridad del coseno\n",
    "- El problema con este modelo, es que necesita mucha memoria de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Preprocesamiento y vectorización\n",
    "#textos = df_ML['genres']\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#matriz_tfidf = vectorizer.fit_transform(textos)\n",
    "\n",
    "# Paso 2: Reducción de dimensionalidad con PCA\n",
    "#ipca = IncrementalPCA(n_components=20)  # Por ejemplo, reduce a 50 componentes\n",
    "#matriz_ipca = ipca.fit_transform(matriz_tfidf)\n",
    "\n",
    "\n",
    "# Paso 3: Cálculo de similitud del coseno después de PCA\n",
    "#similitud_pca = cosine_similarity(matriz_ipca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similitud = similitud_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtramos el dataframe solo con los datos que tengan valor 2 en sentiment_analysis y que sea True en recommend\n",
    "#ya que demanda mucha memoria RAM\n",
    "#df_ML=df_ML[df_ML['sentiment_analysis']==2]\n",
    "#df_ML=df_ML[df_ML['recommend']== True]\n",
    "#Igualmente haciendo ese filtrado de datos, sigue sin poder funcionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def obtener_recomendaciones(titulo, n=5):\n",
    "#    indice_titulo = df_ML[df_ML['app_name'] == titulo].index[0]\n",
    "#    similitudes_titulo = similitud[indice_titulo]\n",
    "#    indices_recomendaciones = similitudes_titulo.argsort()[-n-1:-1][::-1]\n",
    "#    recomendaciones = df_ML.loc[indices_recomendaciones, 'app_name']\n",
    "    \n",
    "    # Convierte la serie en un diccionario\n",
    "#    recomendaciones_dict = recomendaciones.to_dict()\n",
    "\n",
    "#    return recomendaciones_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de machine learning FUNCIONAL <br>\n",
    "Importamos la librería pickle ya que vamos a guardar el modelo de entrenamiento en un archivo .pkl (el cual es un archivo de formato binario que se utiliza para modelos de entrenamiento)para asi luego crear la función de recomendación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia del codificador\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Cargar los datos\n",
    "df_ml = pd.read_csv(\"df_ML.csv\")\n",
    "# Crear una nueva columna llamada genres_encoded, que tiene los generos codificados como int.\n",
    "df_ml[\"genres_encoded\"] = label_encoder.fit_transform(df_ml[\"genres\"])\n",
    "\n",
    "# Crear un diccionario de los títulos asociados a cada item_id\n",
    "titles_by_item_id = {}\n",
    "for i in range(len(df_ml)):\n",
    "    titles_by_item_id[df_ml.loc[i, \"item_id\"]] = df_ml.loc[i, \"app_name\"]\n",
    "\n",
    "# Crear el modelo K-Nearest Neighbors\n",
    "k = 5\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(df_ml[['genres_encoded']], df_ml['app_name'])\n",
    "\n",
    "# Guardar el modelo\n",
    "with open('modelo.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Guardar el diccionario\n",
    "with open('titles_by_item_id.pkl', 'wb') as f:\n",
    "    pickle.dump(titles_by_item_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(item_id: int):\n",
    "\n",
    "    # Cargar el modelo \n",
    "    with open(\"modelo.pkl\", \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    # Cargar el diccionario de títulos\n",
    "    with open(\"titles_by_item_id.pkl\", \"rb\") as f:\n",
    "        titles_by_item_id = pickle.load(f)\n",
    "\n",
    "    # Buscar el género codificado del juego proporcionado por el usuario\n",
    "    input_game = df_ml[df_ml[\"item_id\"] == item_id][\"genres_encoded\"].values[0]\n",
    "\n",
    "    # Encontrar los juegos más similares\n",
    "    _, indices = model.kneighbors([[input_game]])\n",
    "\n",
    "    # Obtener los títulos de los juegos similares\n",
    "    similar_games = [titles_by_item_id[df_ml.loc[i, \"item_id\"]] for i in indices[0]]\n",
    "\n",
    "    # Devolver un diccionario de los títulos\n",
    "    return {\"similar_games\": similar_games}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'similar_games': ['Half-Life',\n",
       "  'Half-Life',\n",
       "  \"Tom Clancy's Rainbow Six® Siege\",\n",
       "  'Half-Life',\n",
       "  'Half-Life']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
