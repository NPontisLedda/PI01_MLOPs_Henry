{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se converten los 3 datasets en dataframes, primero se desanida todo el código porque vienen en una lista en formato .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo una lista vacía para almacenar los datos del archivo JSON\n",
    "juegos = [] \n",
    "#Abro el archivo JSON en modo lectura, y con el bucle for se lee línea por línea\n",
    "with open('output_steam_games.json') as file:\n",
    "    for line in file: \n",
    "        data = json.loads(line)\n",
    "        #Añadimos cada objeto a la lista creada en un principio\n",
    "        juegos.append(data)\n",
    "\n",
    "#Se crea el dataframe con los datos de la lista\n",
    "df_juegos = pd.DataFrame(juegos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificamos si hay valores nulos en el df para poder eliminarlos\n",
    "#df_juegos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a eliminar todos los valores nulos que tenemos en el df\n",
    "#Utilizamos el método .dropna(inplace=True),\n",
    "#el inplace=True es para que la eliminación se realice sobre el original y no se genere un nuevo df\n",
    "df_juegos.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resenias = []\n",
    "with open('australian_user_reviews.json', 'r', encoding = 'utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        resenias.append(ast.literal_eval(line))\n",
    "\n",
    "df_reviews = pd.DataFrame(resenias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "with open('australian_users_items.json', 'r', encoding = 'utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        items.append(ast.literal_eval(line))\n",
    "\n",
    "df_items = pd.DataFrame(items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se normalizan los dataframes\n",
    "\n",
    "- Se explotan las columnas anidadas para dividirlas en múltiples columnas y se unen al dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfresenias_exploded = df_reviews.explode('reviews')\n",
    "dfresenias_normalized = pd.json_normalize(dfresenias_exploded['reviews'])\n",
    "dfresenias_exploded.reset_index(drop=True, inplace=True)\n",
    "dfresenias_normalized.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dfresenias_final= pd.concat([dfresenias_exploded.drop('reviews', axis=1), dfresenias_normalized], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_exploded = df_items.explode('items')\n",
    "df_items_normalized = pd.json_normalize(df_items_exploded['items'])\n",
    "df_items_exploded.reset_index(drop=True, inplace=True)\n",
    "df_items_normalized.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dfitems_final= pd.concat([df_items.drop('items', axis=1), df_items_normalized], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "juegos_exploded = df_juegos.explode('genres')\n",
    "juegos_normalized = pd.json_normalize(juegos_exploded['genres'])\n",
    "juegos_exploded.reset_index(drop=True, inplace=True)\n",
    "juegos_normalized.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_juegos_final = pd.concat([df_juegos, juegos_normalized], axis=1, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres          0\n",
      "app_name        0\n",
      "title           0\n",
      "release_date    0\n",
      "id              0\n",
      "developer       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_juegos_final.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino columnas innecesarias de juegos\n",
    "\n",
    "df_juegos_final.drop(columns=['publisher'], inplace=True)\n",
    "df_juegos_final.drop(columns=['url'], inplace=True)\n",
    "df_juegos_final.drop(columns=['tags'], inplace=True)\n",
    "df_juegos_final.drop(columns=['price'], inplace=True)\n",
    "df_juegos_final.drop(columns=['specs'], inplace=True)\n",
    "df_juegos_final.drop(columns=['early_access'], inplace=True)\n",
    "df_juegos_final.drop(columns=['reviews_url'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino nulos que se encontraron \n",
    "df_juegos_final=df_juegos_final.dropna(subset=['genres'])\n",
    "df_juegos_final=df_juegos_final.dropna(subset=['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>playtime_forever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>js41637</td>\n",
       "      <td>20</td>\n",
       "      <td>Team Fortress Classic</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evcentric</td>\n",
       "      <td>30</td>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Riot-Punch</td>\n",
       "      <td>40</td>\n",
       "      <td>Deathmatch Classic</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doctr</td>\n",
       "      <td>50</td>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88305</th>\n",
       "      <td>76561198323066619</td>\n",
       "      <td>202090</td>\n",
       "      <td>Magicka: Wizard Wars</td>\n",
       "      <td>1501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88306</th>\n",
       "      <td>76561198326700687</td>\n",
       "      <td>239220</td>\n",
       "      <td>The Mighty Quest For Epic Loot</td>\n",
       "      <td>2374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88307</th>\n",
       "      <td>XxLaughingJackClown77xX</td>\n",
       "      <td>257730</td>\n",
       "      <td>Infinity Wars - Animated Trading Card Game</td>\n",
       "      <td>654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88308</th>\n",
       "      <td>76561198329548331</td>\n",
       "      <td>227220</td>\n",
       "      <td>Sang-Froid - Tales of Werewolves</td>\n",
       "      <td>2973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88309</th>\n",
       "      <td>edward_tremethick</td>\n",
       "      <td>233740</td>\n",
       "      <td>Organ Trail: Director's Cut</td>\n",
       "      <td>943.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88310 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id item_id  \\\n",
       "0            76561197970982479      10   \n",
       "1                      js41637      20   \n",
       "2                    evcentric      30   \n",
       "3                   Riot-Punch      40   \n",
       "4                        doctr      50   \n",
       "...                        ...     ...   \n",
       "88305        76561198323066619  202090   \n",
       "88306        76561198326700687  239220   \n",
       "88307  XxLaughingJackClown77xX  257730   \n",
       "88308        76561198329548331  227220   \n",
       "88309        edward_tremethick  233740   \n",
       "\n",
       "                                        item_name  playtime_forever  \n",
       "0                                  Counter-Strike               6.0  \n",
       "1                           Team Fortress Classic               0.0  \n",
       "2                                   Day of Defeat               7.0  \n",
       "3                              Deathmatch Classic               0.0  \n",
       "4                       Half-Life: Opposing Force               0.0  \n",
       "...                                           ...               ...  \n",
       "88305                        Magicka: Wizard Wars            1501.0  \n",
       "88306              The Mighty Quest For Epic Loot            2374.0  \n",
       "88307  Infinity Wars - Animated Trading Card Game             654.0  \n",
       "88308            Sang-Froid - Tales of Werewolves            2973.0  \n",
       "88309                 Organ Trail: Director's Cut             943.0  \n",
       "\n",
       "[88310 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfitems_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminoo columnas innecesarias de items\n",
    "dfitems_final.drop(columns=['user_url'], inplace=True)\n",
    "dfitems_final.drop(columns=['playtime_2weeks'], inplace=True)\n",
    "dfitems_final.drop(columns=['steam_id'], inplace=True)\n",
    "dfitems_final.drop(columns=['items_count'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino nulos en items\n",
    "dfitems_final=dfitems_final.dropna(subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id      0\n",
      "posted       0\n",
      "item_id      0\n",
      "recommend    0\n",
      "review       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dfresenias_final.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino columnas innecesarias de resenias\n",
    "dfresenias_final.drop(columns=['user_url'], inplace=True)\n",
    "dfresenias_final.drop(columns=['funny'], inplace=True)\n",
    "dfresenias_final.drop(columns=['last_edited'], inplace=True)\n",
    "dfresenias_final.drop(columns=['helpful'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino valores nulos de resenias\n",
    "dfresenias_final=dfresenias_final.dropna(subset=['item_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creo la columna de 'sentiment_analysis' en dfresenias_final, aplicando análisis de sentimiento con NLP calculando el puntaje de polaridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargamos los recursos necesarios para NLTK (solo es necesario la primera vez)\n",
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_3672\\1186812390.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfresenias_final['sentiment_analysis']= dfresenias_final['review'].apply(analyze_sentiment_or_default)\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_3672\\1186812390.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfresenias_final.drop(columns=['review'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Se crea el analizador de sentimientos\n",
    "\n",
    "sia= SentimentIntensityAnalyzer()\n",
    "\n",
    "#Función para aplicar el análisis de sentimiento\n",
    "\n",
    "def analyze_sentiment_or_default(text):\n",
    "    if isinstance(text,str):\n",
    "        compound_score = sia.polarity_scores(text)['compound']\n",
    "        if compound_score >= 0.05:\n",
    "            return 2\n",
    "        elif compound_score <= -0.05:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "#Aplicamos el análisis sobre la columna 'review' y creamos la columna 'sentiment_analysis', que va a reemplazar a la columna review.\n",
    "\n",
    "dfresenias_final['sentiment_analysis']= dfresenias_final['review'].apply(analyze_sentiment_or_default)\n",
    "dfresenias_final.drop(columns=['review'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guardan los datasets provisionales para hacer las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_juegos_final.to_csv('juegos_funciones.csv')\n",
    "dfitems_final.to_csv('items_funciones.csv')\n",
    "dfresenias_final.to_csv('resenias_funciones.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrimos los archivos csv para utilizarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_juegos = pd.read_csv('juegos_funciones.csv')\n",
    "df_items = pd.read_csv('items_funciones.csv')\n",
    "df_resenias = pd.read_csv('resenias_funciones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genres', 'app_name', 'title', 'release_date', 'item_id', 'developer'], dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_juegos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'item_id', 'item_name', 'playtime_forever'], dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'posted', 'item_id', 'recommend', 'sentiment_analysis'], dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resenias.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se analiza si hay valores nulos en las columnas\n",
    "- Se limpian las columnas que se utilizarán para no tener valores nulos y se transforma el tipo de dato de fechas para que sea manejable\n",
    "- Eliminamos columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan las columnas que se agregaron con los índices al momento de crear el nuevo csv\n",
    "df_resenias.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_items.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_juegos.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos si hay valores nulos en cada dataframe\n",
    "#print(df_juegos.isnull().sum()) \n",
    "#print(df_resenias.isnull().sum()) \n",
    "#print(df_items.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino nulos de items\n",
    "df_items = df_items.dropna(subset=['item_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio el tipo de dato de la columna release_date\n",
    "df_juegos['release_date'] = df_juegos['release_date'].apply(pd.to_datetime,format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio de nombre la columna id para luego poder hacer el merge\n",
    "df_juegos = df_juegos.rename(columns={\"id\": \"item_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se sacan los valores que tengan en platime_forever 0.0\n",
    "df_items=df_items[df_items['playtime_forever'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge para funciones 1 y 2(juegos e items)\n",
    "\n",
    "juegos_items= pd.merge(df_juegos, df_items, on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge para funciones 3, 4 y 5(juegos y resenias)\n",
    "\n",
    "juegos_resenias= pd.merge(df_juegos,df_resenias,on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos los valores nulos de release_date\n",
    "\n",
    "#juegos_resenias = juegos_resenias.dropna(subset=['release_date'])\n",
    "#juegos_items = juegos_items.dropna(subset=['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo los nuevos datos definitivos para las funciones en archivos .csv\n",
    "\n",
    "juegos_resenias.to_csv('df_f3_4_5.csv')\n",
    "juegos_items.to_csv('df_f1_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos df para funciones 1 y 2 del archivo df_f1_2.csv\n",
    "\n",
    "df_f1_2= pd.read_csv('df_f1_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48889 entries, 0 to 48888\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   genres            48889 non-null  object \n",
      " 1   app_name          48889 non-null  object \n",
      " 2   title             48889 non-null  object \n",
      " 3   release_date      48889 non-null  object \n",
      " 4   item_id           48889 non-null  int64  \n",
      " 5   developer         48889 non-null  object \n",
      " 6   user_id           48889 non-null  object \n",
      " 7   item_name         48889 non-null  object \n",
      " 8   playtime_forever  48889 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_f1_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f1_2['genres'] = df_f1_2['genres'].apply(lambda x: x.replace(\"'\", \"\").strip(\"[]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f1_2.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f1_2['release_date']= df_f1_2['release_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f1_2['release_date'] = pd.to_datetime(df_f1_2['release_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera función\n",
    "-  Indicación: def PlayTimeGenre(genero:str): Debe devolver año con mas horas jugadas para dicho género. <br> Ejemplo de retorno: {\"Año con más horas jugadas para Género X\" : 2013}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlayTimeGenre(genero):\n",
    "    genero = genero.lower()\n",
    "    genero = genero.capitalize()\n",
    "    df_f1_2['release_date'] = pd.to_datetime(df_f1_2['release_date'], errors='coerce')\n",
    "    max_horas_anio = None\n",
    "    max_horas = 0\n",
    "    horas_por_anio = {}\n",
    "    \n",
    "    for index, row in df_f1_2.iterrows():\n",
    "        if genero in row['genres']:\n",
    "            # Obtener el año de la fecha de lanzamiento\n",
    "            year = row['release_date'].year\n",
    "            \n",
    "            # Sumar las horas jugadas\n",
    "            horas_jugadas = row['playtime_forever']\n",
    "            \n",
    "            if year not in horas_por_anio:\n",
    "                horas_por_anio[year] = 0\n",
    "                \n",
    "            horas_por_anio[year] += horas_jugadas\n",
    "            \n",
    "            if horas_por_anio[year] > max_horas:\n",
    "                max_horas = horas_por_anio[year]\n",
    "                max_horas_anio = year\n",
    "    res = {\n",
    "    \"Año con más horas\": max_horas_anio,\"Total de horas sumadas\": max_horas\n",
    "    }\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Año con más horas': 2012, 'Total de horas sumadas': 23939553.0}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PlayTimeGenre('Action')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda función\n",
    "- Indicaciones:  def UserForGenre(genero:str): Debe devolver el usuario que acumula más horas jugadas para el género dado y una lista de la acumulación de horas jugadas por año.<br> Ejemplo de retorno: {\"Usuario con más horas jugadas para Género X\" : us213ndjss09sdf, \"Horas jugadas\":[{Año: 2013, Horas: 203}, {Año: 2012, Horas: 100}, {Año: 2011, Horas: 23}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def UserForGenre(genero):\n",
    "\n",
    "    df_f1_2[\"release_date\"] = pd.to_datetime(df_f1_2[\"release_date\"])\n",
    "    df_f1_2[\"release_year\"] = df_f1_2[\"release_date\"].dt.year\n",
    "\n",
    "    # Filtrar el dataframe por género.\n",
    "    df_filtrado = df_f1_2[df_f1_2[\"genres\"].str.contains(genero)]\n",
    "\n",
    "    # Calcular la acumulación de horas jugadas por usuario.\n",
    "    df_acumulado = df_filtrado.groupby(\"user_id\")[\"playtime_forever\"].sum()\n",
    "\n",
    "    # Obtener el usuario con más horas jugadas.\n",
    "    usuario_mas_horas = df_acumulado.idxmax()\n",
    "\n",
    "    # Calcular la acumulación de horas jugadas por año.\n",
    "    df_acumulado_por_ano_1 = df_filtrado.groupby([\"release_year\"])[\"playtime_forever\"].sum().to_frame()\n",
    "    df_1 = df_acumulado_por_ano_1.add_suffix(\"_Sum\").reset_index()\n",
    "\n",
    "    # Convertir el dataframe a una lista de diccionarios.\n",
    "    df_1 = df_1.rename(columns={\"release_year\": \"Año\", \"playtime_forever_Sum\": \"Horas\"})\n",
    "    lista_acumulado_por_ano = df_1.to_dict(orient=\"records\")\n",
    "\n",
    "    # Devolver el resultado.\n",
    "    return {\n",
    "        \"Usuario con más horas jugadas para Género X\": usuario_mas_horas,\n",
    "        \"Horas jugadas\": lista_acumulado_por_ano\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Usuario con más horas jugadas para Género X': 'gossuper',\n",
       " 'Horas jugadas': [{'Año': 1994, 'Horas': 21.0},\n",
       "  {'Año': 1995, 'Horas': 431.0},\n",
       "  {'Año': 1996, 'Horas': 5.0},\n",
       "  {'Año': 1997, 'Horas': 18.0},\n",
       "  {'Año': 1998, 'Horas': 87.0},\n",
       "  {'Año': 2003, 'Horas': 6620.0},\n",
       "  {'Año': 2005, 'Horas': 3094.0},\n",
       "  {'Año': 2006, 'Horas': 6117.0},\n",
       "  {'Año': 2007, 'Horas': 7550.0},\n",
       "  {'Año': 2008, 'Horas': 15892.0},\n",
       "  {'Año': 2009, 'Horas': 34854.0},\n",
       "  {'Año': 2010, 'Horas': 76373.0},\n",
       "  {'Año': 2011, 'Horas': 16011.0},\n",
       "  {'Año': 2012, 'Horas': 30078.0},\n",
       "  {'Año': 2013, 'Horas': 89352.0},\n",
       "  {'Año': 2014, 'Horas': 147882.0},\n",
       "  {'Año': 2015, 'Horas': 845215.0},\n",
       "  {'Año': 2016, 'Horas': 66370.0},\n",
       "  {'Año': 2017, 'Horas': 343.0}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UserForGenre('Racing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abro el archivo con el que voy a trabajar en las funciones 3, 4 y 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f3_4_5= pd.read_csv('df_f3_4_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino columnas innecesarias\n",
    "df_f3_4_5.drop(columns='Unnamed: 0',inplace=True)\n",
    "df_f3_4_5.drop(columns='title',inplace=True)\n",
    "df_f3_4_5.drop(columns='release_date',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f3_4_5['genres'] = df_f3_4_5['genres'].apply(lambda x: x.replace(\"'\", \"\").strip(\"[]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_732\\1974894324.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  string = df_f3_4_5.iloc[i][5]\n"
     ]
    }
   ],
   "source": [
    "#Obtengo el año de la columna posted y se crea la columna posted_year\n",
    "df_f3_4_5.dropna(inplace=True)\n",
    "lista=[]\n",
    "for i in range(0,len(df_f3_4_5)):\n",
    "    string = df_f3_4_5.iloc[i][5]\n",
    "\n",
    "    try:\n",
    "      b = int(string[-5:-1])\n",
    "    except ValueError:\n",
    "      b = float('nan') \n",
    "\n",
    "    lista.append(b)\n",
    "\n",
    "df_f3_4_5['posted_year'] = lista\n",
    "df_f3_4_5.dropna(inplace=True)\n",
    "df_f3_4_5['posted_year'] = df_f3_4_5['posted_year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino la columna posted\n",
    "df_f3_4_5.drop(columns='posted', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tercera función\n",
    "- def UsersRecommend( año : int ): Devuelve el top 3 de juegos MÁS recomendados por usuarios para el año dado. (reviews.recommend = True y comentarios positivos/neutrales) <br>\n",
    "Ejemplo de retorno: [{\"Puesto 1\" : X}, {\"Puesto 2\" : Y},{\"Puesto 3\" : Z}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UsersRecommend(year: int):\n",
    "    # Verificar si el año es igual a -1 y mostrar un mensaje personalizado\n",
    "    if year == -1:\n",
    "        return \"El año ingresado es -1, lo cual no es válido.\"\n",
    "\n",
    "    # Verificar que el año sea un número entero\n",
    "    if not isinstance(year, int):\n",
    "        return \"El año debe ser un número entero.\"\n",
    "\n",
    "    # Verificar que el año ingresado esté en la columna 'posted_year'\n",
    "    if year not in df_f3_4_5['posted_year'].unique():\n",
    "        return \"El año no se encuentra en la columna 'posted_year'.\"\n",
    "\n",
    "    # Filtrar el dataset para obtener solo las filas correspondientes al año dado\n",
    "    juegos_del_año = df_f3_4_5[df_f3_4_5['posted_year'] == year]\n",
    "\n",
    "    # Calcular la cantidad de recomendaciones para cada juego\n",
    "    recomendaciones_por_juego = juegos_del_año.groupby('app_name')['recommend'].sum().reset_index()\n",
    "\n",
    "    # Ordenar los juegos por la cantidad de recomendaciones en orden descendente\n",
    "    juegos_ordenados = recomendaciones_por_juego.sort_values(by='recommend', ascending=False)\n",
    "\n",
    "    # Tomar los tres primeros lugares\n",
    "    primer_puesto = juegos_ordenados.iloc[0]['app_name']\n",
    "    segundo_puesto = juegos_ordenados.iloc[1]['app_name']\n",
    "    tercer_puesto = juegos_ordenados.iloc[2]['app_name']\n",
    "\n",
    "    # Crear el diccionario con los tres primeros lugares\n",
    "    top_tres = {\n",
    "        \"Puesto 1\": primer_puesto,\n",
    "        \"Puesto 2\": segundo_puesto,\n",
    "        \"Puesto 3\": tercer_puesto\n",
    "    }\n",
    "\n",
    "    return top_tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Puesto 1': 'Counter-Strike: Global Offensive',\n",
       " 'Puesto 2': 'Team Fortress 2',\n",
       " 'Puesto 3': \"Garry's Mod\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UsersRecommend(2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuarta función\n",
    "- def UsersWorstDeveloper( año : int ): Devuelve el top 3 de desarrolladoras con juegos MENOS recomendados por usuarios para el año dado. (reviews.recommend = False y comentarios negativos) <br>\n",
    "Ejemplo de retorno: [{\"Puesto 1\" : X}, {\"Puesto 2\" : Y},{\"Puesto 3\" : Z}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UsersWorstDeveloper(año: int):\n",
    "    # Verificar si el año es igual a -1 y mostrar un mensaje personalizado\n",
    "    if año == -1:\n",
    "        return \"El año ingresado es -1, lo cual no es válido.\"\n",
    "\n",
    "    # Verificar que el año sea un número entero\n",
    "    if not isinstance(año, int):\n",
    "        return \"El año debe ser un número entero.\"\n",
    "\n",
    "    # Verificar que el año ingresado esté en la columna 'posted_year'\n",
    "    if año not in df_f3_4_5['posted_year'].unique():\n",
    "        return \"El año no se encuentra en la columna 'posted_year'.\"\n",
    "\n",
    "    # Filtrar el dataset para obtener solo las filas correspondientes al año dado\n",
    "    juegos_del_año = df_f3_4_5[df_f3_4_5['posted_year'] == año]\n",
    "\n",
    "    # Calcular la cantidad de recomendaciones para cada developer\n",
    "    recomendaciones_por_juego = juegos_del_año.groupby('developer')['recommend'].sum().reset_index()\n",
    "\n",
    "    # Ordenar los juegos por la cantidad de recomendaciones en orden descendente\n",
    "    devs_ordenados = recomendaciones_por_juego.sort_values(by='recommend', ascending=True)\n",
    "\n",
    "    # Tomar los tres primeros lugares\n",
    "    ultimo_puesto = devs_ordenados.iloc[0]['developer']\n",
    "    penultimo_puesto = devs_ordenados.iloc[1]['developer']\n",
    "    antepenultimo_puesto = devs_ordenados.iloc[2]['developer']\n",
    "\n",
    "    # Crear el diccionario con los tres primeros lugares\n",
    "    ultimos_tres = {\n",
    "        \"Puesto 1\": ultimo_puesto,\n",
    "        \"Puesto 2\": penultimo_puesto,\n",
    "        \"Puesto 3\": antepenultimo_puesto\n",
    "    }\n",
    "\n",
    "    return ultimos_tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Puesto 1': 'Bitl,Cobalt-57',\n",
       " 'Puesto 2': 'Lazy Bum Games',\n",
       " 'Puesto 3': 'Sometimes You'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UsersWorstDeveloper(2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quinta función\n",
    "- def sentiment_analysis( empresa desarrolladora : str ): Según la empresa desarrolladora, se devuelve un diccionario con el nombre de la desarrolladora como llave y una lista con la cantidad total de registros de reseñas de usuarios que se encuentren categorizados con un análisis de sentimiento como valor. <br>\n",
    "Ejemplo de retorno: {'Valve' : [Negative = 182, Neutral = 120, Positive = 278]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(devs:str):\n",
    "\n",
    "    # Filtrar el DataFrame por la desarrolladora ingresada\n",
    "    df_devs = df_f3_4_5[df_f3_4_5['developer'] == devs]\n",
    "\n",
    "    # Verificar si se encontraron registros para el año\n",
    "    if df_devs.empty:\n",
    "        return {\"Mensaje\": \"No se encontraron registros para la desarrolladora especificada.\"}\n",
    "\n",
    "    # Contar la cantidad de registros para cada categoría de análisis de sentimiento\n",
    "    sentiment_analysis_column = df_devs['sentiment_analysis']\n",
    "    sentiment = sentiment_analysis_column.value_counts().to_dict()\n",
    "\n",
    "    # Crear una lista con los resultados, tuve que colocar en formato de str todo para que me lo tomara como válido \n",
    "    resultado= list([\"Negative= \"+ str(sentiment.get(0, 0)), \"Neutral= \"+ str(sentiment.get(1, 0)), \"Positive= \"+ str(sentiment.get(2, 0))])\n",
    "\n",
    "    #Crear el diccionario final\n",
    "    result = {\n",
    "        devs:resultado\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Valve': ['Negative= 929', 'Neutral= 2049', 'Positive= 5393']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis('Valve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un dataset exclusivo para machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML= pd.merge(df_f1_2,df_f3_4_5,on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ML.drop(columns='posted_year',inplace=True)\n",
    "df_ML.drop(columns='user_id_y',inplace=True)\n",
    "df_ML.drop(columns='developer_y',inplace=True)\n",
    "df_ML.drop(columns='app_name_y',inplace=True)\n",
    "df_ML.drop(columns='genres_y',inplace=True)\n",
    "df_ML.drop(columns='item_name',inplace=True)\n",
    "df_ML.drop(columns='release_date',inplace=True)\n",
    "df_ML.drop(columns='title',inplace=True)\n",
    "df_ML.drop(columns='release_year',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ML = df_ML.rename(columns={\"genres_x\": \"genres\"})\n",
    "df_ML = df_ML.rename(columns={\"app_name_x\": \"app_name\"})\n",
    "df_ML = df_ML.rename(columns={\"developer_x\": \"developer\"})\n",
    "df_ML = df_ML.rename(columns={\"user_id_x\": \"user_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el dataset en un archivo csv\n",
    "#df_ML.to_csv('df_ML.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA <br>\n",
    "\n",
    "- Se buscan outliers en variables de cantidad, solo se encuentra en 'playtime_forever' usando .describe() y se eliminan los mayores a 6500 horas de juego ya que es muy poco probable que alguien dedique tantas horas de juego diarias a lo largo de 5 años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda=pd.read_csv('df_ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_eda.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>playtime_forever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33333.000000</td>\n",
       "      <td>33333.000000</td>\n",
       "      <td>33333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>166942.891729</td>\n",
       "      <td>1.476075</td>\n",
       "      <td>2104.298593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>132670.561269</td>\n",
       "      <td>0.754684</td>\n",
       "      <td>9856.081973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6830.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>212070.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>261880.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>919.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>527340.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>400827.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             item_id  sentiment_analysis  playtime_forever\n",
       "count   33333.000000        33333.000000      33333.000000\n",
       "mean   166942.891729            1.476075       2104.298593\n",
       "std    132670.561269            0.754684       9856.081973\n",
       "min        10.000000            0.000000          1.000000\n",
       "25%      6830.000000            1.000000         46.000000\n",
       "50%    212070.000000            2.000000        225.000000\n",
       "75%    261880.000000            2.000000        919.000000\n",
       "max    527340.000000            2.000000     400827.000000"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eda.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sin_outliers_2= df_eda[df_eda['playtime_forever']<6500.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_outliers=df_sin_outliers_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el dataset con el trabajo de EDA\n",
    "\n",
    "df_sin_outliers.to_csv('df_EDA.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
